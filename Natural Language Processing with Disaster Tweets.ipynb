{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e999b849-0b62-438b-a5c0-a3297544b3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9106936-0c93-442e-9380-bfc5bf601da4",
   "metadata": {},
   "source": [
    "### Brief description of the problem and data\n",
    "\n",
    "Briefly describe the challenge problem and NLP. Describe the size, dimension, structure, etc., of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584460f5-a3ec-47ac-9eab-3e4da58bf3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcc97940-d086-4f1d-a122-def25f6686a3",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA) — Inspect, Visualize and Clean the Data\n",
    "\n",
    "Show a few visualizations like histograms. Describe any data cleaning procedures. Based on your EDA, what is your plan of analysis? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f5a46-86cd-405d-a408-692d8739406d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "583d13d6-6b34-4ec4-a94c-a838ae74ce5f",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "Describe your model architecture and reasoning for why you believe that specific architecture would be suitable for this problem. \n",
    "\n",
    "Since we did not learn NLP-specific techniques such as word embeddings in the lectures, we recommend looking at Kaggle tutorials, discussion boards, and code examples posted for this challenge.  You can use any resources needed, but make sure you “demonstrate” you understood by including explanations in your own words. Also importantly, please have a reference list at the end of the report.  \n",
    "\n",
    "There are many methods to process texts to matrix form (word embedding), including TF-IDF, GloVe, Word2Vec, etc. Pick a strategy and process the raw texts to word embedding. Briefly explain the method(s) and how they work in your own words.\n",
    "\n",
    "Build and train your sequential neural network model (You may use any RNN family neural network, including advanced architectures LSTM, GRU, bidirectional RNN, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf93d3a-36a7-4e59-bf12-d6703dac13f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb142e7d-1411-451a-8cf8-b6e32fd6b446",
   "metadata": {},
   "source": [
    "### Results and Analysis\n",
    "\n",
    "Run hyperparameter tuning, try different architectures for comparison, apply techniques to improve training or performance, and discuss what helped.\n",
    "\n",
    "Includes results with tables and figures. There is an analysis of why or why not something worked well, troubleshooting, and a hyperparameter optimization procedure summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8bd60a-c334-48a6-9d66-f1c2015191ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c0d2598-a977-47bb-910f-fb001f5adb6b",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Discuss and interpret results as well as learnings and takeaways. What did and did not help improve the performance of your models? What improvements could you try in the future?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defbc839-8647-410f-b440-cf020d7767a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
